{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "910b19f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "breast_cancer = fetch_ucirepo(id=14)\n",
    "\n",
    "X = breast_cancer.data.features\n",
    "y = breast_cancer.data.targets\n",
    "df = breast_cancer.data.original\n",
    "variables = breast_cancer.variables['name']\n",
    "\n",
    "def simpleSample(data):\n",
    "    testing = data.groupby('Class', group_keys=False).sample(frac=0.2)\n",
    "    learning = data.drop(testing.index)\n",
    "    return learning, testing\n",
    "\n",
    "def fold10Sample(data):\n",
    "    folds = []\n",
    "    for i in range(0,10):\n",
    "        folds.append(data.groupby('Class', group_keys=False).sample(4))\n",
    "        data = data.drop(folds[i].index)\n",
    "    return folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4b2678eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprune(df):\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "24087cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprune(df):\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9c8eb7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, results=None, branches=None):\n",
    "        self.feature = feature  # Feature to split on\n",
    "        self.results = results  # Stores class labels if node is a leaf node\n",
    "        self.branches = branches  # Branch for values that are True for the feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3afe114a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('deg-malig', np.float64(0.07700985251661441))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def laplaceSmoothing(data, t):\n",
    "    l = 1\n",
    "    totals = t.copy()\n",
    "    additive = [l] * data.shape[0]\n",
    "    data[['no-recurrence-events', 'recurrence-events']] = data[['no-recurrence-events', 'recurrence-events']]*totals\n",
    "    for col in data.columns: \n",
    "        if 0 in data[col].values:\n",
    "            totals[col] += l*data.shape[0]\n",
    "            data[col] = data[col].add(additive)\n",
    "            data['total'] = data['total'].add(additive)\n",
    "    data[['no-recurrence-events', 'recurrence-events']] /= totals\n",
    "    return data\n",
    "\n",
    "def creatFrequencyTables(data, smoothing):\n",
    "    frequencyTable = {}\n",
    "    frequencyTable['Class'] = data['Class'].value_counts(dropna=False, ascending=True).to_frame()\n",
    "    for category in data.columns:\n",
    "        if category == 'Class':\n",
    "            continue\n",
    "        else:\n",
    "            temp = data[['Class',category]].value_counts(dropna=False)\n",
    "            frequencyTable[category] = pd.DataFrame({'no-recurrence-events':temp['no-recurrence-events'], 'recurrence-events':temp['recurrence-events']})\n",
    "            frequencyTable[category].fillna(0, inplace=True)\n",
    "            frequencyTable[category]['total'] = frequencyTable[category]['no-recurrence-events'] + frequencyTable[category]['recurrence-events']\n",
    "            #frequencyTable[category][['no-recurrence-events', 'recurrence-events']] /= frequencyTable['Class']['count']\n",
    "            if smoothing and any([0 in sublist for sublist in frequencyTable[category].values]):\n",
    "                frequencyTable[category] = laplaceSmoothing(frequencyTable[category], frequencyTable['Class']['count'])\n",
    "    return frequencyTable\n",
    "\n",
    "def entropy(a,b):\n",
    "    sum = a + b\n",
    "    a = a/sum\n",
    "    b = b/sum\n",
    "    return -(a*np.log2(a) if a != 0 else 0)- (b*np.log2(b) if b != 0 else 0)\n",
    "\n",
    "def entropyTableGenerator(df):\n",
    "    frequency = creatFrequencyTables(df, False)\n",
    "    entropyTable = {}\n",
    "    for category in frequency:\n",
    "        if category == 'Class':\n",
    "            entropyTable[category] = entropy(frequency[category]['count']['no-recurrence-events'],frequency[category]['count']['recurrence-events'])\n",
    "        else:\n",
    "            entropyTable[category] = frequency[category].apply(lambda x: entropy(x['no-recurrence-events'], x['recurrence-events']), axis=1)\n",
    "            entropyTable[category] *= frequency[category]['total'].div(frequency[category]['total'].sum())\n",
    "            entropyTable[category] = entropyTable[category].sum()\n",
    "\n",
    "    return entropyTable\n",
    "\n",
    "\n",
    "def informationGainTableGenerator(entropyTable):\n",
    "    informationGain = {}\n",
    "    for category in entropyTable:\n",
    "        if category == 'Class':\n",
    "            continue\n",
    "\n",
    "        informationGain[category] = entropyTable['Class'] - entropyTable[category]\n",
    "    #return informationGain\n",
    "    maxkey = max(informationGain, key=informationGain.get)\n",
    "    return maxkey, informationGain[maxkey]\n",
    "\n",
    "informationGainTableGenerator(entropyTableGenerator(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "493d3802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, feature):\n",
    "    result = {}\n",
    "    for discription in data[feature].drop_duplicates():\n",
    "        result[discription] = data[feature == discription]\n",
    "    return result\n",
    "\n",
    "def buildtree(data):\n",
    "    if data.shape[0] == 1:\n",
    "        return Node(results=data['Class'][0])\n",
    "    \n",
    "    bestFeature, bestGain = informationGainTableGenerator(entropyTableGenerator(data))\n",
    "\n",
    "    if bestGain > 0:\n",
    "        branchesData = split_data(data, bestFeature)\n",
    "        branches = {}\n",
    "        for discription in branchesData:\n",
    "            branches[discription] = buildtree(branchesData[discription])\n",
    "        return Node(feature=bestFeature, branches=branches)\n",
    "    \n",
    "    return Node(results=data['Class'][0])\n",
    "\n",
    "\n",
    "def id3(training, testing):\n",
    "    decisionTree = buildtree(training)\n",
    "\n",
    "    def predict(tree, sample):\n",
    "        if tree.results is not None:\n",
    "            return tree.results\n",
    "        else:\n",
    "            branch = tree.branches[sample[tree.feature]]\n",
    "            return predict(branch, sample)\n",
    "    \n",
    "    return testing.apply(lambda x: predict(decisionTree, x), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "67ef12da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158    50-59\n",
      "120    60-69\n",
      "55     70-79\n",
      "137    40-49\n",
      "118    30-39\n",
      "Name: age, dtype: object\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "False",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bugyb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: False",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[157]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m divisor = validate.shape[\u001b[32m0\u001b[39m]\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(validate[\u001b[33m'\u001b[39m\u001b[33mage\u001b[39m\u001b[33m'\u001b[39m].drop_duplicates())\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m validate[\u001b[33m'\u001b[39m\u001b[33mresult\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mid3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m success = validate[validate[\u001b[33m'\u001b[39m\u001b[33mresult\u001b[39m\u001b[33m'\u001b[39m] == validate[\u001b[33m'\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m'\u001b[39m]].shape[\u001b[32m0\u001b[39m]\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m1.Train Set Accuracy:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAccuracy:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{:.2%}\u001b[39;00m\u001b[33m\"\u001b[39m.format(success/divisor))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[156]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mid3\u001b[39m\u001b[34m(training, testing)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mid3\u001b[39m(training, testing):\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     decisionTree = \u001b[43mbuildtree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(tree, sample):\n\u001b[32m     27\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m tree.results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[156]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mbuildtree\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m     11\u001b[39m bestFeature, bestGain = informationGainTableGenerator(entropyTableGenerator(data))\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m bestGain > \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     branchesData = \u001b[43msplit_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbestFeature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     branches = {}\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m discription \u001b[38;5;129;01min\u001b[39;00m branchesData:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[156]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36msplit_data\u001b[39m\u001b[34m(data, feature)\u001b[39m\n\u001b[32m      2\u001b[39m result = {}\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m discription \u001b[38;5;129;01min\u001b[39;00m data[feature].drop_duplicates():\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     result[discription] = \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscription\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bugyb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bugyb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: False"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# m = input(\"Mode?\")\n",
    "# m = int(m)\n",
    "m = 0\n",
    "if m == 0:\n",
    "    d = preprune(df)\n",
    "elif m == 1:\n",
    "    d = postprune(df)\n",
    "elif m == 2:\n",
    "    d = postprune(preprune(df))\n",
    "else:\n",
    "    sys.exit(\"Not a valid mode\")\n",
    "    \n",
    "data, testing = simpleSample(d)\n",
    "_ , validate = simpleSample(data)\n",
    "\n",
    "divisor = validate.shape[0]\n",
    "print(validate['age'].drop_duplicates())\n",
    "validate['result'] = id3(data, validate)\n",
    "success = validate[validate['result'] == validate['Class']].shape[0]\n",
    "\n",
    "print(\"1.Train Set Accuracy:\\nAccuracy:\", \"{:.2%}\".format(success/divisor))\n",
    "\n",
    "print(\"\\n2.10-Fold Cross-Validation Results:\")\n",
    "folds = fold10Sample(data)\n",
    "successes = [0] * 10\n",
    "for i in range(0,10):\n",
    "    divisor = folds[i].shape[0]\n",
    "    folds[i]['result'] = id3(data.drop(folds[i].index), folds[i])\n",
    "    successes[i] = folds[i][folds[i]['result'] == folds[i]['Class']].shape[0]/divisor\n",
    "    print(\"Accuracy Fold\", i+1, \":\", \"{:.2%}\".format(successes[i]))\n",
    "\n",
    "print(\"\\nAverage Accuracy:\",  \"{:.2%}\".format(np.average(successes)))\n",
    "print(\"Standard Deviation:\",  \"{:.2%}\".format(np.std(successes)))\n",
    "\n",
    "testing['result'] = id3(data, testing)\n",
    "success = testing[testing['result'] == testing['Class']].shape[0]\n",
    "divisor = testing.shape[0]\n",
    "print(\"\\n3.Test Set Accuracy:\\nAccuracy:\", \"{:.2%}\".format(success/divisor))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72466c91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "910b19f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "breast_cancer = fetch_ucirepo(id=14)\n",
    "\n",
    "X = breast_cancer.data.features\n",
    "y = breast_cancer.data.targets\n",
    "df = breast_cancer.data.original\n",
    "variables = breast_cancer.variables['name']\n",
    "df.fillna(\"?\", inplace=True)\n",
    "# df['node-caps'].fillna(df['node-caps'].mode(), inplace=True)\n",
    "# df['breast-quad'].fillna(df['breast-quad'].mode(), inplace=True)\n",
    "def simpleSample(data):\n",
    "    testing = data.groupby('Class', group_keys=False).sample(frac=0.2)\n",
    "    learning = data.drop(testing.index)\n",
    "    return learning, testing\n",
    "\n",
    "def fold10Sample(data):\n",
    "    folds = []\n",
    "    for i in range(0,10):\n",
    "        folds.append(data.groupby('Class', group_keys=False).sample(4))\n",
    "        data = data.drop(folds[i].index)\n",
    "    return folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c8eb7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, results=None, branches=None, n_samples = 0, errors = 0):\n",
    "        self.feature = feature \n",
    "        self.results = results \n",
    "        self.branches = branches \n",
    "        self.n_samples = n_samples\n",
    "        self.errors = errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3afe114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplaceSmoothing(data, t):\n",
    "    l = 1\n",
    "    totals = t.copy()\n",
    "    additive = [l] * data.shape[0]\n",
    "    data[['no-recurrence-events', 'recurrence-events']] = data[['no-recurrence-events', 'recurrence-events']]*totals\n",
    "    for col in data.columns: \n",
    "        if 0 in data[col].values:\n",
    "            totals[col] += l*data.shape[0]\n",
    "            data[col] = data[col].add(additive)\n",
    "            data['total'] = data['total'].add(additive)\n",
    "    data[['no-recurrence-events', 'recurrence-events']] /= totals\n",
    "    return data\n",
    "\n",
    "def creatFrequencyTables(data, smoothing):\n",
    "    frequencyTable = {}\n",
    "    frequencyTable['Class'] = data['Class'].value_counts(dropna=False, ascending=True).to_frame()\n",
    "    if frequencyTable['Class'].shape[0] == 1:\n",
    "        return \"no entropy\"\n",
    "    for category in data.columns:\n",
    "        if category == 'Class':\n",
    "            continue\n",
    "        else:\n",
    "            temp = data[['Class',category]].value_counts(dropna=False)\n",
    "            frequencyTable[category] = pd.DataFrame({'no-recurrence-events':temp['no-recurrence-events'], 'recurrence-events':temp['recurrence-events']})\n",
    "            frequencyTable[category].fillna(0, inplace=True)\n",
    "            frequencyTable[category]['total'] = frequencyTable[category]['no-recurrence-events'] + frequencyTable[category]['recurrence-events']\n",
    "            #frequencyTable[category][['no-recurrence-events', 'recurrence-events']] /= frequencyTable['Class']['count']\n",
    "            if smoothing and any([0 in sublist for sublist in frequencyTable[category].values]):\n",
    "                frequencyTable[category] = laplaceSmoothing(frequencyTable[category], frequencyTable['Class']['count'])\n",
    "    return frequencyTable\n",
    "\n",
    "def entropy(a,b):\n",
    "    sum = a + b\n",
    "    a = a/sum\n",
    "    b = b/sum\n",
    "    return -(a*np.log2(a) if a != 0 else 0)- (b*np.log2(b) if b != 0 else 0)\n",
    "\n",
    "def entropyTableGenerator(df):\n",
    "    frequency = creatFrequencyTables(df, False)\n",
    "\n",
    "    if frequency == \"no entropy\":\n",
    "        return frequency\n",
    "\n",
    "    entropyTable = {}\n",
    "    for category in frequency:\n",
    "        if category == 'Class':\n",
    "            entropyTable[category] = entropy(frequency[category]['count']['no-recurrence-events'],frequency[category]['count']['recurrence-events'])\n",
    "        else:\n",
    "            entropyTable[category] = frequency[category].apply(lambda x: entropy(x['no-recurrence-events'], x['recurrence-events']), axis=1)\n",
    "            entropyTable[category] *= frequency[category]['total'].div(frequency[category]['total'].sum())\n",
    "            entropyTable[category] = entropyTable[category].sum()\n",
    "\n",
    "    return entropyTable\n",
    "\n",
    "\n",
    "def informationGainTableGenerator(entropyTable):\n",
    "    if entropyTable == 'no entropy':\n",
    "        return entropyTable, entropyTable\n",
    "\n",
    "    informationGain = {}\n",
    "    for category in entropyTable:\n",
    "        if category == 'Class':\n",
    "            continue\n",
    "\n",
    "        informationGain[category] = entropyTable['Class'] - entropyTable[category]\n",
    "    #return informationGain\n",
    "    maxkey = max(informationGain, key=informationGain.get)\n",
    "    return maxkey, informationGain[maxkey]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24087cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getErrorEstimate(node, is_subtree=False):\n",
    "    if node.results is not None or not is_subtree:\n",
    "        # Single node error: (E + 0.5) / n\n",
    "        return (node.errors + 0.45) / node.n_samples  \n",
    "\n",
    "    leaf_errors, leaf_count, total_n = sumLeafStats(node)\n",
    "    return (leaf_errors + (0.5 * leaf_count)) / total_n  \n",
    "\n",
    "def sumLeafStats(node):\n",
    "    if node.results is not None:\n",
    "        return node.errors, 1, node.n_samples\n",
    "    \n",
    "    total_e, total_l, total_n = 0, 0, 0\n",
    "    for child in node.branches.values():\n",
    "        e, l, n = sumLeafStats(child)\n",
    "        total_e += e\n",
    "        total_l += l\n",
    "        total_n += n\n",
    "    return total_e, total_l, total_n\n",
    "\n",
    "def postpruning(node):\n",
    "    if node.results is not None:\n",
    "        return\n",
    "    \n",
    "    for child in node.branches.values():\n",
    "        postpruning(child)\n",
    "\n",
    "    canPrune = all(child.results is not None for child in node.branches.values())\n",
    "\n",
    "    if canPrune:\n",
    "        error_subtree = getErrorEstimate(node, is_subtree=True)\n",
    "        error_leaf = getErrorEstimate(node, is_subtree=False)\n",
    "\n",
    "        if error_leaf <= error_subtree:\n",
    "            node.results = node.branches['default'].results\n",
    "            node.branches = {}\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "493d3802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, feature):\n",
    "    result = {}\n",
    "    for discription in data[feature].drop_duplicates():\n",
    "        result[discription] = data[data[feature] == discription]\n",
    "    return result\n",
    "\n",
    "def buildtree(data, minimumGain):\n",
    "    if data.shape[0] == 1:\n",
    "        return Node(results=data['Class'].values[0], n_samples=1)\n",
    "    \n",
    "    bestFeature, bestGain = informationGainTableGenerator(entropyTableGenerator(data))\n",
    "    if bestFeature == 'no entropy':\n",
    "        return Node(results=data['Class'].values[0], n_samples=data.shape[0])\n",
    "    \n",
    "    # print(bestFeature, bestGain)\n",
    "    if bestGain > minimumGain:\n",
    "        branchesData = split_data(data, bestFeature)\n",
    "        branches = {'default':Node(results=data[\"Class\"].mode().values[0], n_samples=data.shape[0])}\n",
    "        branches['default'].errors = data[data['Class'] != branches['default'].results].shape[0]\n",
    "        for discription in branchesData:\n",
    "            # print(bestFeature ,\" discription = \", discription)\n",
    "            branches[discription] = buildtree(branchesData[discription], minimumGain)\n",
    "        return Node(feature=bestFeature, branches=branches, n_samples=data.shape[0], errors=data[data['Class'] != branches['default'].results].shape[0])\n",
    "    \n",
    "    return Node(results=data['Class'].values[0],n_samples=1)\n",
    "\n",
    "\n",
    "def id3(training, testing, minimumGain, postprune):\n",
    "    decisionTree = buildtree(training, minimumGain)\n",
    "\n",
    "    if postprune:\n",
    "        postpruning(decisionTree)\n",
    "\n",
    "    def predict(tree, sample):\n",
    "        if tree.results is not None:\n",
    "            return tree.results\n",
    "        else:\n",
    "            if sample[tree.feature] not in tree.branches:\n",
    "                return tree.branches['default'].results \n",
    "            branch = tree.branches[sample[tree.feature]]\n",
    "            return predict(branch, sample)\n",
    "    \n",
    "    return testing.apply(lambda x: predict(decisionTree, x), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ef12da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.Train Set Accuracy:\n",
      "Accuracy: 97.83%\n",
      "\n",
      "2.10-Fold Cross-Validation Results:\n",
      "Accuracy Fold 1 : 25.00%\n",
      "Accuracy Fold 2 : 37.50%\n",
      "Accuracy Fold 3 : 50.00%\n",
      "Accuracy Fold 4 : 62.50%\n",
      "Accuracy Fold 5 : 37.50%\n",
      "Accuracy Fold 6 : 37.50%\n",
      "Accuracy Fold 7 : 25.00%\n",
      "Accuracy Fold 8 : 62.50%\n",
      "Accuracy Fold 9 : 37.50%\n",
      "Accuracy Fold 10 : 50.00%\n",
      "\n",
      "Average Accuracy: 42.50%\n",
      "Standard Deviation: 12.75%\n",
      "\n",
      "3.Test Set Accuracy:\n",
      "Accuracy: 68.42%\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# m = input(\"Mode?\")\n",
    "# m = int(m)\n",
    "m = 2\n",
    "if m == 0:\n",
    "    postprune = False\n",
    "    minimumGain = 0.07\n",
    "elif m == 1:\n",
    "    postprune = True\n",
    "    minimumGain = 0\n",
    "elif m == 2:\n",
    "    postprune = True\n",
    "    minimumGain = 0.07\n",
    "else:\n",
    "    sys.exit(\"Not a valid mode\")\n",
    "    \n",
    "data, testing = simpleSample(df)\n",
    "_ , validate = simpleSample(data)\n",
    "\n",
    "divisor = validate.shape[0]\n",
    "\n",
    "validate['result'] = id3(data, validate, minimumGain, postprune)\n",
    "success = validate[validate['result'] == validate['Class']].shape[0]\n",
    "\n",
    "print(\"1.Train Set Accuracy:\\nAccuracy:\", \"{:.2%}\".format(success/divisor))\n",
    "\n",
    "print(\"\\n2.10-Fold Cross-Validation Results:\")\n",
    "folds = fold10Sample(data)\n",
    "successes = [0] * 10\n",
    "for i in range(0,10):\n",
    "    divisor = folds[i].shape[0]\n",
    "    folds[i]['result'] = id3(data.drop(folds[i].index), folds[i], minimumGain, postprune)\n",
    "    successes[i] = folds[i][folds[i]['result'] == folds[i]['Class']].shape[0]/divisor\n",
    "    print(\"Accuracy Fold\", i+1, \":\", \"{:.2%}\".format(successes[i]))\n",
    "\n",
    "print(\"\\nAverage Accuracy:\",  \"{:.2%}\".format(np.average(successes)))\n",
    "print(\"Standard Deviation:\",  \"{:.2%}\".format(np.std(successes)))\n",
    "\n",
    "testing['result'] = id3(data, testing, minimumGain, postprune)\n",
    "success = testing[testing['result'] == testing['Class']].shape[0]\n",
    "divisor = testing.shape[0]\n",
    "print(\"\\n3.Test Set Accuracy:\\nAccuracy:\", \"{:.2%}\".format(success/divisor))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72466c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no-recurrence-events\n"
     ]
    }
   ],
   "source": [
    "# for u in df['age'].drop_duplicates():\n",
    "#     print(u, df[df['age'] == u])\n",
    "# branchData = split_data(df, 'age')\n",
    "# for discription in branchData:\n",
    "#     print(branchData[discription])\n",
    "\n",
    "#print(data.dtypes)\n",
    "# selection = data.loc[(data['tumor-size'] == '30-34') & (data['inv-nodes'] == '0-2') & (data['breast-quad'] == 'left_low') & (data['age'] == '50-59')]\n",
    "# first = selection['Class'].head(1)\n",
    "# print(first[0])\n",
    "\n",
    "print(data[\"Class\"].mode().values[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

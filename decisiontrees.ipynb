{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b19f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "breast_cancer = fetch_ucirepo(id=14)\n",
    "\n",
    "X = breast_cancer.data.features\n",
    "y = breast_cancer.data.targets\n",
    "df = breast_cancer.data.original\n",
    "variables = breast_cancer.variables['name']\n",
    "df.fillna(\"?\", inplace=True)\n",
    "# df['node-caps'].fillna(df['node-caps'].mode(), inplace=True)\n",
    "# df['breast-quad'].fillna(df['breast-quad'].mode(), inplace=True)\n",
    "def simpleSample(data):\n",
    "    testing = data.groupby('Class', group_keys=False).sample(frac=0.2)\n",
    "    learning = data.drop(testing.index)\n",
    "    return learning, testing\n",
    "\n",
    "def fold10Sample(data):\n",
    "    folds = []\n",
    "    for i in range(0,10):\n",
    "        folds.append(data.groupby('Class', group_keys=False).sample(4))\n",
    "        data = data.drop(folds[i].index)\n",
    "    return folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "9c8eb7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, results=None, branches=None, n_samples = 0, errors = 0):\n",
    "        self.feature = feature \n",
    "        self.results = results \n",
    "        self.branches = branches \n",
    "        self.n_samples = n_samples\n",
    "        self.errors = errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "3afe114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplaceSmoothing(data, t):\n",
    "    l = 1\n",
    "    totals = t.copy()\n",
    "    additive = [l] * data.shape[0]\n",
    "    data[['no-recurrence-events', 'recurrence-events']] = data[['no-recurrence-events', 'recurrence-events']]*totals\n",
    "    for col in data.columns: \n",
    "        if 0 in data[col].values:\n",
    "            totals[col] += l*data.shape[0]\n",
    "            data[col] = data[col].add(additive)\n",
    "            data['total'] = data['total'].add(additive)\n",
    "    data[['no-recurrence-events', 'recurrence-events']] /= totals\n",
    "    return data\n",
    "\n",
    "def creatFrequencyTables(data, smoothing):\n",
    "    frequencyTable = {}\n",
    "    frequencyTable['Class'] = data['Class'].value_counts(dropna=False, ascending=True).to_frame()\n",
    "    if frequencyTable['Class'].shape[0] == 1:\n",
    "        return \"no entropy\"\n",
    "    for category in data.columns:\n",
    "        if category == 'Class':\n",
    "            continue\n",
    "        else:\n",
    "            temp = data[['Class',category]].value_counts(dropna=False)\n",
    "            frequencyTable[category] = pd.DataFrame({'no-recurrence-events':temp['no-recurrence-events'], 'recurrence-events':temp['recurrence-events']})\n",
    "            frequencyTable[category].fillna(0, inplace=True)\n",
    "            frequencyTable[category]['total'] = frequencyTable[category]['no-recurrence-events'] + frequencyTable[category]['recurrence-events']\n",
    "            #frequencyTable[category][['no-recurrence-events', 'recurrence-events']] /= frequencyTable['Class']['count']\n",
    "            if smoothing and any([0 in sublist for sublist in frequencyTable[category].values]):\n",
    "                frequencyTable[category] = laplaceSmoothing(frequencyTable[category], frequencyTable['Class']['count'])\n",
    "    return frequencyTable\n",
    "\n",
    "def entropy(a,b):\n",
    "    sum = a + b\n",
    "    a = a/sum\n",
    "    b = b/sum\n",
    "    return -(a*np.log2(a) if a != 0 else 0)- (b*np.log2(b) if b != 0 else 0)\n",
    "\n",
    "def entropyTableGenerator(df):\n",
    "    frequency = creatFrequencyTables(df, False)\n",
    "\n",
    "    if frequency == \"no entropy\":\n",
    "        return frequency\n",
    "\n",
    "    entropyTable = {}\n",
    "    for category in frequency:\n",
    "        if category == 'Class':\n",
    "            entropyTable[category] = entropy(frequency[category]['count']['no-recurrence-events'],frequency[category]['count']['recurrence-events'])\n",
    "        else:\n",
    "            entropyTable[category] = frequency[category].apply(lambda x: entropy(x['no-recurrence-events'], x['recurrence-events']), axis=1)\n",
    "            entropyTable[category] *= frequency[category]['total'].div(frequency[category]['total'].sum())\n",
    "            entropyTable[category] = entropyTable[category].sum()\n",
    "\n",
    "    return entropyTable\n",
    "\n",
    "\n",
    "def informationGainTableGenerator(entropyTable):\n",
    "    if entropyTable == 'no entropy':\n",
    "        return entropyTable, entropyTable\n",
    "\n",
    "    informationGain = {}\n",
    "    for category in entropyTable:\n",
    "        if category == 'Class':\n",
    "            continue\n",
    "\n",
    "        informationGain[category] = entropyTable['Class'] - entropyTable[category]\n",
    "    #return informationGain\n",
    "    maxkey = max(informationGain, key=informationGain.get)\n",
    "    return maxkey, informationGain[maxkey]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "24087cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getErrorEstimate(node, is_subtree=False):\n",
    "    if node.results is not None or not is_subtree:\n",
    "        # Single node error: (E + 0.5) / n\n",
    "        return (node.errors + 0.5) / node.n_samples  \n",
    "\n",
    "    leaf_errors, leaf_count, total_n = sumLeafStats(node)\n",
    "    return (leaf_errors + (0.5 * leaf_count)) / total_n  \n",
    "\n",
    "def sumLeafStats(node):\n",
    "    if node.results is not None:\n",
    "        return node.errors, 1, node.n_samples\n",
    "    \n",
    "    total_e, total_l, total_n = 0, 0, 0\n",
    "    for child in node.branches.values():\n",
    "        e, l, n = sumLeafStats(child)\n",
    "        total_e += e\n",
    "        total_l += l\n",
    "        total_n += n\n",
    "    return total_e, total_l, total_n\n",
    "\n",
    "def postpruning(node):\n",
    "    if node.results is not None:\n",
    "        return\n",
    "    \n",
    "    for child in node.branches.values():\n",
    "        postpruning(child)\n",
    "\n",
    "    canPrune = all(child.results is not None for child in node.branches.values())\n",
    "\n",
    "    if canPrune:\n",
    "        error_subtree = getErrorEstimate(node, is_subtree=True)\n",
    "        error_leaf = getErrorEstimate(node, is_subtree=False)\n",
    "\n",
    "        if error_leaf <= error_subtree:\n",
    "            node.results = node.branches['default']\n",
    "            node.branches = {}\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "493d3802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, feature):\n",
    "    result = {}\n",
    "    for discription in data[feature].drop_duplicates():\n",
    "        result[discription] = data[data[feature] == discription]\n",
    "    return result\n",
    "\n",
    "def buildtree(data, minimumGain):\n",
    "    if data.shape[0] == 1:\n",
    "        return Node(results=data['Class'].values[0], n_samples=1)\n",
    "    \n",
    "    bestFeature, bestGain = informationGainTableGenerator(entropyTableGenerator(data))\n",
    "    if bestFeature == 'no entropy':\n",
    "        return Node(results=data['Class'].values[0], n_samples=data.shape[0])\n",
    "    \n",
    "    # print(bestFeature, bestGain)\n",
    "    if bestGain > minimumGain:\n",
    "        branchesData = split_data(data, bestFeature)\n",
    "        branches = {'default':Node(results=data[\"Class\"].mode().values[0], n_samples=data.shape[0])}\n",
    "        branches['default'].errors = data[data['Class'] != branches['default'].results].shape[0]\n",
    "        for discription in branchesData:\n",
    "            # print(bestFeature ,\" discription = \", discription)\n",
    "            branches[discription] = buildtree(branchesData[discription], minimumGain)\n",
    "        return Node(feature=bestFeature, branches=branches, n_samples=data.shape[0], errors=data[data['Class'] != branches['default'].results].shape[0])\n",
    "    \n",
    "    return Node(results=data['Class'].values[0],n_samples=1)\n",
    "\n",
    "\n",
    "def id3(training, testing, minimumGain, postprune):\n",
    "    decisionTree = buildtree(training, minimumGain)\n",
    "\n",
    "    if postprune:\n",
    "        postpruning(decisionTree)\n",
    "\n",
    "    def predict(tree, sample):\n",
    "        if tree.results is not None:\n",
    "            return tree.results\n",
    "        else:\n",
    "            if sample[tree.feature] not in tree.branches:\n",
    "                return tree.branches['default'] \n",
    "            branch = tree.branches[sample[tree.feature]]\n",
    "            return predict(branch, sample)\n",
    "    \n",
    "    return testing.apply(lambda x: predict(decisionTree, x), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "67ef12da",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'no-recurrence-events'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bugyb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'no-recurrence-events'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[540]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     18\u001b[39m _ , validate = simpleSample(data)\n\u001b[32m     20\u001b[39m divisor = validate.shape[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m validate[\u001b[33m'\u001b[39m\u001b[33mresult\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mid3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminimumGain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprune\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m success = validate[validate[\u001b[33m'\u001b[39m\u001b[33mresult\u001b[39m\u001b[33m'\u001b[39m] == validate[\u001b[33m'\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m'\u001b[39m]].shape[\u001b[32m0\u001b[39m]\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m1.Train Set Accuracy:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAccuracy:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{:.2%}\u001b[39;00m\u001b[33m\"\u001b[39m.format(success/divisor))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[539]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mid3\u001b[39m\u001b[34m(training, testing, minimumGain, postprune)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mid3\u001b[39m(training, testing, minimumGain, postprune):\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     decisionTree = \u001b[43mbuildtree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminimumGain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m postprune:\n\u001b[32m     32\u001b[39m         postpruning(decisionTree)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[539]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mbuildtree\u001b[39m\u001b[34m(data, minimumGain)\u001b[39m\n\u001b[32m     19\u001b[39m     branches[\u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m].errors = data[data[\u001b[33m'\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m'\u001b[39m] != branches[\u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m].results].shape[\u001b[32m0\u001b[39m]\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m discription \u001b[38;5;129;01min\u001b[39;00m branchesData:\n\u001b[32m     21\u001b[39m         \u001b[38;5;66;03m# print(bestFeature ,\" discription = \", discription)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m         branches[discription] = \u001b[43mbuildtree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbranchesData\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdiscription\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminimumGain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Node(feature=bestFeature, branches=branches, n_samples=data.shape[\u001b[32m0\u001b[39m], errors=data[data[\u001b[33m'\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m'\u001b[39m] != branches[\u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m].results].shape[\u001b[32m0\u001b[39m])\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Node(results=data[\u001b[33m'\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m'\u001b[39m].values[\u001b[32m0\u001b[39m],n_samples=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[539]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mbuildtree\u001b[39m\u001b[34m(data, minimumGain)\u001b[39m\n\u001b[32m     19\u001b[39m     branches[\u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m].errors = data[data[\u001b[33m'\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m'\u001b[39m] != branches[\u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m].results].shape[\u001b[32m0\u001b[39m]\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m discription \u001b[38;5;129;01min\u001b[39;00m branchesData:\n\u001b[32m     21\u001b[39m         \u001b[38;5;66;03m# print(bestFeature ,\" discription = \", discription)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m         branches[discription] = \u001b[43mbuildtree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbranchesData\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdiscription\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminimumGain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Node(feature=bestFeature, branches=branches, n_samples=data.shape[\u001b[32m0\u001b[39m], errors=data[data[\u001b[33m'\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m'\u001b[39m] != branches[\u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m].results].shape[\u001b[32m0\u001b[39m])\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Node(results=data[\u001b[33m'\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m'\u001b[39m].values[\u001b[32m0\u001b[39m],n_samples=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[539]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mbuildtree\u001b[39m\u001b[34m(data, minimumGain)\u001b[39m\n\u001b[32m     19\u001b[39m     branches[\u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m].errors = data[data[\u001b[33m'\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m'\u001b[39m] != branches[\u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m].results].shape[\u001b[32m0\u001b[39m]\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m discription \u001b[38;5;129;01min\u001b[39;00m branchesData:\n\u001b[32m     21\u001b[39m         \u001b[38;5;66;03m# print(bestFeature ,\" discription = \", discription)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m         branches[discription] = \u001b[43mbuildtree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbranchesData\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdiscription\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminimumGain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Node(feature=bestFeature, branches=branches, n_samples=data.shape[\u001b[32m0\u001b[39m], errors=data[data[\u001b[33m'\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m'\u001b[39m] != branches[\u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m].results].shape[\u001b[32m0\u001b[39m])\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Node(results=data[\u001b[33m'\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m'\u001b[39m].values[\u001b[32m0\u001b[39m],n_samples=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[539]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mbuildtree\u001b[39m\u001b[34m(data, minimumGain)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data.shape[\u001b[32m0\u001b[39m] == \u001b[32m1\u001b[39m:\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Node(results=data[\u001b[33m'\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m'\u001b[39m].values[\u001b[32m0\u001b[39m], n_samples=\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m bestFeature, bestGain = informationGainTableGenerator(\u001b[43mentropyTableGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m bestFeature == \u001b[33m'\u001b[39m\u001b[33mno entropy\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Node(results=data[\u001b[33m'\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m'\u001b[39m].values[\u001b[32m0\u001b[39m], n_samples=data.shape[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[537]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mentropyTableGenerator\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mentropyTableGenerator\u001b[39m(df):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     frequency = \u001b[43mcreatFrequencyTables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m frequency == \u001b[33m\"\u001b[39m\u001b[33mno entropy\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     42\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m frequency\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[537]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mcreatFrequencyTables\u001b[39m\u001b[34m(data, smoothing)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     23\u001b[39m     temp = data[[\u001b[33m'\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m'\u001b[39m,category]].value_counts(dropna=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     frequencyTable[category] = pd.DataFrame({\u001b[33m'\u001b[39m\u001b[33mno-recurrence-events\u001b[39m\u001b[33m'\u001b[39m:\u001b[43mtemp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mno-recurrence-events\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[33m'\u001b[39m\u001b[33mrecurrence-events\u001b[39m\u001b[33m'\u001b[39m:temp[\u001b[33m'\u001b[39m\u001b[33mrecurrence-events\u001b[39m\u001b[33m'\u001b[39m]})\n\u001b[32m     25\u001b[39m     frequencyTable[category].fillna(\u001b[32m0\u001b[39m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     26\u001b[39m     frequencyTable[category][\u001b[33m'\u001b[39m\u001b[33mtotal\u001b[39m\u001b[33m'\u001b[39m] = frequencyTable[category][\u001b[33m'\u001b[39m\u001b[33mno-recurrence-events\u001b[39m\u001b[33m'\u001b[39m] + frequencyTable[category][\u001b[33m'\u001b[39m\u001b[33mrecurrence-events\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bugyb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\series.py:1133\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[key]\n\u001b[32m   1132\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[32m-> \u001b[39m\u001b[32m1133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[32m   1136\u001b[39m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[32m   1137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bugyb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\series.py:1249\u001b[39m, in \u001b[36mSeries._get_value\u001b[39m\u001b[34m(self, label, takeable)\u001b[39m\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[label]\n\u001b[32m   1248\u001b[39m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[32m   1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bugyb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:3059\u001b[39m, in \u001b[36mMultiIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3056\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mask\n\u001b[32m   3058\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m3059\u001b[39m     loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_level_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3060\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _maybe_to_slice(loc)\n\u001b[32m   3062\u001b[39m keylen = \u001b[38;5;28mlen\u001b[39m(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bugyb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:3410\u001b[39m, in \u001b[36mMultiIndex._get_level_indexer\u001b[39m\u001b[34m(self, key, level, indexer)\u001b[39m\n\u001b[32m   3407\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(i, j, step)\n\u001b[32m   3409\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3410\u001b[39m     idx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_loc_single_level_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3412\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m level > \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lexsort_depth == \u001b[32m0\u001b[39m:\n\u001b[32m   3413\u001b[39m         \u001b[38;5;66;03m# Desired level is not sorted\u001b[39;00m\n\u001b[32m   3414\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mslice\u001b[39m):\n\u001b[32m   3415\u001b[39m             \u001b[38;5;66;03m# test_get_loc_partial_timestamp_multiindex\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bugyb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:2999\u001b[39m, in \u001b[36mMultiIndex._get_loc_single_level_index\u001b[39m\u001b[34m(self, level_index, key)\u001b[39m\n\u001b[32m   2997\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m -\u001b[32m1\u001b[39m\n\u001b[32m   2998\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2999\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlevel_index\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bugyb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'no-recurrence-events'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# m = input(\"Mode?\")\n",
    "# m = int(m)\n",
    "m = 2\n",
    "if m == 0:\n",
    "    postprune = False\n",
    "    minimumGain = 0.07\n",
    "elif m == 1:\n",
    "    postprune = True\n",
    "    minimumGain = 0\n",
    "elif m == 2:\n",
    "    postprune = True\n",
    "    minimumGain = 0.07\n",
    "else:\n",
    "    sys.exit(\"Not a valid mode\")\n",
    "    \n",
    "data, testing = simpleSample(df)\n",
    "_ , validate = simpleSample(data)\n",
    "\n",
    "divisor = validate.shape[0]\n",
    "\n",
    "validate['result'] = id3(data, validate, minimumGain, postprune)\n",
    "success = validate[validate['result'] == validate['Class']].shape[0]\n",
    "\n",
    "print(\"1.Train Set Accuracy:\\nAccuracy:\", \"{:.2%}\".format(success/divisor))\n",
    "\n",
    "print(\"\\n2.10-Fold Cross-Validation Results:\")\n",
    "folds = fold10Sample(data)\n",
    "successes = [0] * 10\n",
    "for i in range(0,10):\n",
    "    divisor = folds[i].shape[0]\n",
    "    folds[i]['result'] = id3(data.drop(folds[i].index), folds[i], minimumGain, postprune)\n",
    "    successes[i] = folds[i][folds[i]['result'] == folds[i]['Class']].shape[0]/divisor\n",
    "    print(\"Accuracy Fold\", i+1, \":\", \"{:.2%}\".format(successes[i]))\n",
    "\n",
    "print(\"\\nAverage Accuracy:\",  \"{:.2%}\".format(np.average(successes)))\n",
    "print(\"Standard Deviation:\",  \"{:.2%}\".format(np.std(successes)))\n",
    "\n",
    "testing['result'] = id3(data, testing, minimumGain, postprune)\n",
    "success = testing[testing['result'] == testing['Class']].shape[0]\n",
    "divisor = testing.shape[0]\n",
    "print(\"\\n3.Test Set Accuracy:\\nAccuracy:\", \"{:.2%}\".format(success/divisor))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72466c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no-recurrence-events\n"
     ]
    }
   ],
   "source": [
    "# for u in df['age'].drop_duplicates():\n",
    "#     print(u, df[df['age'] == u])\n",
    "# branchData = split_data(df, 'age')\n",
    "# for discription in branchData:\n",
    "#     print(branchData[discription])\n",
    "\n",
    "#print(data.dtypes)\n",
    "# selection = data.loc[(data['tumor-size'] == '30-34') & (data['inv-nodes'] == '0-2') & (data['breast-quad'] == 'left_low') & (data['age'] == '50-59')]\n",
    "# first = selection['Class'].head(1)\n",
    "# print(first[0])\n",
    "\n",
    "print(data[\"Class\"].mode().values[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

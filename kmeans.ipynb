{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "2e1928ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils for algorithms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def euclidianDistance(point, candidate):\n",
    "    return np.linalg.norm(point - candidate)\n",
    "\n",
    "def distances(point, points):\n",
    "    return [euclidianDistance(point, candidate) for candidate in points]\n",
    "\n",
    "def chooseNewCentroid(centroids, cluster, i):\n",
    "    if len(cluster) == 0 :\n",
    "        return centroids[i]\n",
    "    else:\n",
    "        return np.mean(cluster,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "c594c0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMeansShell(dataset, metric, cluster_count, starting_strategy, iterations):\n",
    "    def iteration(centroids):\n",
    "        distance = np.linalg.norm(dataset[:, np.newaxis] - centroids, axis=2)\n",
    "        labels = np.argmin(distance, axis=1)\n",
    "            \n",
    "        indecies = [[i for i,x in enumerate(labels) if x == j ] for j in range(cluster_count)]\n",
    "        clusters = [[p for p in dataset[indecies[i]] ] for i in range(cluster_count)]\n",
    "        new_centroids = [chooseNewCentroid(centroids, cluster, i) for i, cluster in enumerate(clusters)]\n",
    "        change = np.sum([min(distances(p, centroids)) for p in new_centroids])\n",
    "\n",
    "        return new_centroids, labels, clusters, change\n",
    "\n",
    "    best_thus_far = np.inf\n",
    "    for i in range(iterations):\n",
    "        current_centroids = starting_strategy(dataset, cluster_count)\n",
    "        change = 1\n",
    "        while change != 0:\n",
    "            current_centroids, labels, clusters, change = iteration(current_centroids)\n",
    "        \n",
    "        new_metric_result = metric(clusters, current_centroids)\n",
    "        best_thus_far = min(best_thus_far, new_metric_result)\n",
    "        if best_thus_far == new_metric_result:\n",
    "            result_centroids = current_centroids\n",
    "            result_labels = labels\n",
    "            # np.savetxt('centroids.txt', np.array(result_centroids))\n",
    "            # np.savetxt('cluster_labels.txt', np.array(result_labels), fmt=\"%d\")\n",
    "            # %run plot_clusters.py Datasets/unbalance/unbalance.txt centroids.txt cluster_labels.txt\n",
    "\n",
    "    np.savetxt('centroids.txt', np.array(result_centroids))\n",
    "    np.savetxt('cluster_labels.txt', np.array(result_labels), fmt=\"%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "48f6dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMeans(dataset, metric, cluster_count):\n",
    "    def choosing(dataset, cluster_count):\n",
    "        return dataset[np.random.permutation(len(dataset))[:cluster_count]]\n",
    "    \n",
    "    kMeansShell(dataset, metric, cluster_count, choosing,20)\n",
    "\n",
    "def kMeansplusplus(dataset, metric, cluster_count):\n",
    "    def choosing(dataset, cluster_count):\n",
    "        result = [dataset[np.random.choice(range(len(dataset)))]]\n",
    "        while len(result) < cluster_count:\n",
    "            candidateDistances = [np.min(distances(current, result)) for current in dataset]\n",
    "            result.append(dataset[np.argmax(candidateDistances)])\n",
    "\n",
    "        return result\n",
    "    \n",
    "    kMeansShell(dataset, metric, cluster_count, choosing,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd11eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wcss(clusters, centroids):\n",
    "    return np.sum([np.sum(distances(centroids[i], clusters[i])) for i, _ in enumerate(centroids)])\n",
    "\n",
    "def daviesBouldinIndex(clusters, centroids):\n",
    "    size = len(centroids)\n",
    "    s = [np.sum(distances(centroids[i], cluster))*1.0/len(cluster) for i,cluster in enumerate(clusters)]\n",
    "    m = [[euclidianDistance(centroids[i], centroids[j]) for j in range(size)] for i in range(size)]\n",
    "\n",
    "    return np.sum([np.max([(s[i]+s[j])/m[i][j] for j in range(size) if j != i]) for i in range(size)])*1.0/size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "5c266545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils for main\n",
    "\n",
    "def chooseAlgorithm(name):\n",
    "    pairs = {\n",
    "        \"kMeans\" : kMeans,\n",
    "        \"kMeans++\" : kMeansplusplus,\n",
    "    }\n",
    "\n",
    "    return pairs[name]\n",
    "\n",
    "def chooseMetric(number):\n",
    "    pairs = {\n",
    "        \"1\" : wcss,\n",
    "        \"2\" : daviesBouldinIndex,\n",
    "    }\n",
    "\n",
    "    return pairs[number]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568fc8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#inp = input(\"<data_file> <algorithm_name> <metric> <cluster_count>\")\n",
    "inp = \"unbalance.txt kMeans 1 8\"\n",
    "labels = inp.split(\" \")\n",
    "if len(labels) != 4:\n",
    "    sys.exit(\"Not a valid input\")\n",
    "\n",
    "algorithm = chooseAlgorithm(labels[1])\n",
    "metric = chooseMetric(labels[2])\n",
    "\n",
    "labels[0] = \"Datasets\\\\\" + labels[0][:-4] + \"\\\\\" + labels[0]\n",
    "\n",
    "algorithm(np.loadtxt(labels[0]) ,metric, int(labels[3]))\n",
    "\n",
    "%run plot_clusters.py {labels[0]} centroids.txt cluster_labels.txt\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "6299eba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "\n",
    "iris = fetch_ucirepo(id=53)\n",
    "\n",
    "X = iris.data.features\n",
    "y = iris.data.targets\n",
    "df = iris.data.original\n",
    "\n",
    "label_dict = {k: 0 for k in y['class']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "bcc8de6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as math\n",
    "\n",
    "def computeDistance(a, b):\n",
    "    return math.sqrt(math.sum([(ai-bi) ** 2 for ai, bi in zip(a, b)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1d5638c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMajorityLabel(neighboursList):\n",
    "    majority = label_dict.copy()\n",
    "    furthest = neighboursList[-1][0] + 1\n",
    "    for dist, label in neighboursList:\n",
    "        majority[label] += furthest - dist\n",
    "    return max(majority, key=majority.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ce679fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleSample(data):\n",
    "    testing = data.groupby('class', group_keys=False).sample(frac=0.2)\n",
    "    learning = data.drop(testing.index)\n",
    "    return learning, testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "4addaaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold10Sample(data):\n",
    "    folds = []\n",
    "    for i in range(0,10):\n",
    "        folds.append(data.groupby('class', group_keys=False).sample(4))\n",
    "        data.drop(folds[i].index)\n",
    "    return folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "304d4626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNNClassify(X, Y, xt, k):\n",
    "    distancePairList = []\n",
    "    for xi, yi in zip(X.values, Y.values):\n",
    "        di = computeDistance(xi, xt)\n",
    "        distancePairList.append((di, yi))\n",
    "    distancePairList.sort()\n",
    "\n",
    "    kNeighboursList = distancePairList[:k]\n",
    "    yt = getMajorityLabel(kNeighboursList)\n",
    "\n",
    "    return yt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5143e304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.Train Set Accuracy:\n",
      "Accuracy: 95.83%\n",
      "\n",
      "2.10-Fold Cross-Validation Results:\n",
      "Accuracy Fold 1 : 100.00%\n",
      "Accuracy Fold 2 : 91.67%\n",
      "Accuracy Fold 3 : 100.00%\n",
      "Accuracy Fold 4 : 100.00%\n",
      "Accuracy Fold 5 : 100.00%\n",
      "Accuracy Fold 6 : 91.67%\n",
      "Accuracy Fold 7 : 100.00%\n",
      "Accuracy Fold 8 : 100.00%\n",
      "Accuracy Fold 9 : 91.67%\n",
      "Accuracy Fold 10 : 100.00%\n",
      "\n",
      "Average Accuracy: 97.50%\n",
      "Standard Deviation: 3.82%\n",
      "\n",
      "3.Test Set Accuracy:\n",
      "Accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "learning, testing = simpleSample(df)\n",
    "_ , validate = simpleSample(learning)\n",
    "k = input(\"Value?\")\n",
    "k = int(k)\n",
    "success = 0\n",
    "for v in validate.values:\n",
    "    #print(learning.drop('class', axis=1), learning['class'])\n",
    "    ys = kNNClassify(learning.drop('class', axis=1), learning['class'], v[:-1], k )\n",
    "    if ys == v[-1]:\n",
    "        success += 1\n",
    "\n",
    "print(\"1.Train Set Accuracy:\\nAccuracy:\", \"{:.2%}\".format(success/24))\n",
    "\n",
    "print(\"\\n2.10-Fold Cross-Validation Results:\")\n",
    "folds = fold10Sample(learning)\n",
    "successes = [0] * 10\n",
    "for i in range(0,10):\n",
    "    learning = df.drop(folds[i].index)\n",
    "    for t in folds[i].values:\n",
    "        ys = kNNClassify(learning.drop('class', axis=1), learning['class'], t[:-1], k )\n",
    "        if ys == t[-1]:\n",
    "            successes[i] += 1\n",
    "    successes[i] = successes[i]/12\n",
    "    print(\"Accuracy Fold\", i+1, \":\", \"{:.2%}\".format(successes[i]))\n",
    "\n",
    "print(\"\\nAverage Accuracy:\",  \"{:.2%}\".format(np.average(successes)))\n",
    "print(\"Standard Deviation:\",  \"{:.2%}\".format(np.std(successes)))\n",
    "\n",
    "success = 0\n",
    "for t in testing.values:\n",
    "    #print(learning.drop('class', axis=1), learning['class'])\n",
    "    ys = kNNClassify(learning.drop('class', axis=1), learning['class'], t[:-1], k )\n",
    "    if ys == t[-1]:\n",
    "        success += 1\n",
    "\n",
    "print(\"\\n3.Test Set Accuracy:\\nAccuracy:\", \"{:.2%}\".format(success/30))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
